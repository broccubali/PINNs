{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731990115.787535    7678 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (1, 1225)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 1225, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 60\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (1, 1225)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 1225, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Adjust based on your spatial domain\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Adjust based on your temporal domain\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model, x_train[None], t_train[None], x_train[None], t_train[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m           \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m           \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 60\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "\n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train = np.array(np.meshgrid(x_train.flatten(), t_train.flatten())).T.reshape(-1, 2)  # Shape (n_samples, 2)\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model,\n",
    "               X_train,\n",
    "               np.tile(t_train.flatten(), (clean_data.shape[1], 1)).T.flatten()[:, None], \n",
    "               X_train,\n",
    "               np.tile(t_train.flatten(), (noisy_data.shape[1], 1)).T.flatten()[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_noisy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 60\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "\n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train = np.array(np.meshgrid(x_train.flatten(), t_train.flatten())).T.reshape(-1, 2)  # Shape (n_samples, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean and noisy data\n",
    "    T_clean = np.tile(t_train.flatten(), (clean_data.shape[1], 1)).T.flatten()[:, None]\n",
    "    T_noisy = np.tile(t_train.flatten(), (noisy_data.shape[1], 1)).T.flatten()[:, None]\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model,\n",
    "               X_train,\n",
    "               T_clean,\n",
    "               X_train,\n",
    "               T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_noisy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 60\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 60\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "\n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train = np.array(np.meshgrid(x_train.flatten(), t_train.flatten())).T.reshape(-1, 2)  # Shape (n_samples, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean and noisy data\n",
    "    T_clean = np.tile(t_train.flatten(), (clean_data.shape[1], 1)).T.flatten()[:, None]\n",
    "    T_noisy = np.tile(t_train.flatten(), (noisy_data.shape[1], 1)).T.flatten()[:, None]\n",
    "\n",
    "    # Ensure that X_train has the correct shape for both clean and noisy datasets.\n",
    "    assert X_train.shape[1] == 2  # Check that X_train has two columns\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model,\n",
    "               X_train,\n",
    "               T_clean,\n",
    "               X_train,\n",
    "               T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_noisy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 61\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[10], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "\n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train = np.array(np.meshgrid(x_train.flatten(), t_train.flatten())).T.reshape(-1, 2)  # Shape (n_samples, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean and noisy data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape (205824,)\n",
    "    T_noisy = np.tile(t_train.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape (205824,)\n",
    "    \n",
    "    # Ensure that X_train has the correct shape for both clean and noisy datasets.\n",
    "    assert X_train.shape[1] == 2  # Check that X_train has two columns\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model,\n",
    "               X_train,\n",
    "               T_clean,\n",
    "               X_train,\n",
    "               T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "T_noisy shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m pinn_model \u001b[38;5;241m=\u001b[39m create_pinn_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data first then on noisy data\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_noisy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 61\u001b[0m         loss_clean \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_clean, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train_clean, t_train_clean, x_train_noisy, t_train_noisy):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Training on clean data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_clean = physics_loss(model, x_train_clean, t_train_clean)\n",
    "        \n",
    "        grads = tape.gradient(loss_clean, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Clean Loss: {loss_clean.numpy()}')\n",
    "\n",
    "    # Training on noisy data\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_noisy = physics_loss(model, x_train_noisy, t_train_noisy)\n",
    "        \n",
    "        grads = tape.gradient(loss_noisy, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Noisy Loss: {loss_noisy.numpy()}')\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "\n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train = np.array(np.meshgrid(x_train.flatten(), t_train.flatten())).T.reshape(-1, 2)  # Shape (n_samples, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean and noisy data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    T_noisy = np.tile(t_train.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness\n",
    "    print(\"X_train shape:\", X_train.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)      # Should be (205824, 1)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)      # Should be (205824, 1)\n",
    "\n",
    "    # Ensure that X_train has the correct shape for both clean and noisy datasets.\n",
    "    assert X_train.shape[1] == 2  # Check that X_train has two columns\n",
    "\n",
    "    # Create PINN model\n",
    "    pinn_model = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on clean data first then on noisy data\n",
    "    train_pinn(pinn_model,\n",
    "               X_train,\n",
    "               T_clean,\n",
    "               X_train,\n",
    "               T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on clean data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_18\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m           \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_train_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Flattened temporal input\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    109\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    110\u001b[0m                  X_train_clean,\n\u001b[1;32m    111\u001b[0m                  np\u001b[38;5;241m.\u001b[39mtile(t_train_clean\u001b[38;5;241m.\u001b[39mflatten(), (clean_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],))\u001b[38;5;241m.\u001b[39mflatten()[:, \u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "Cell \u001b[0;32mIn[15], line 61\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 61\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphysics_loss\u001b[39m(model, x_train, t_train):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_18\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "    # Prepare temporal inputs for noisy data\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201, 1))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "               X_train_clean,\n",
    "               np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None])   # Flattened temporal input\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                     X_train_clean,\n",
    "                     np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None])\n",
    "\n",
    "    \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "               X_train_noisy,\n",
    "               np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None])   # Flattened temporal input\n",
    "\n",
    "   # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                    X_train_noisy,\n",
    "                    np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_21\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m           \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m           \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    117\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    118\u001b[0m                  X_train_clean,\n\u001b[1;32m    119\u001b[0m                  T_clean)\n",
      "Cell \u001b[0;32mIn[19], line 65\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 65\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     68\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[19], line 35\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhysics loss input shapes - x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_21\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201, 1))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "               X_train_clean,\n",
    "               T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                     X_train_clean,\n",
    "                     T_clean)\n",
    "\n",
    "    \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "              X_train_noisy,\n",
    "              T_noisy)\n",
    "\n",
    "   # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                    X_train_noisy,\n",
    "                    T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    121\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    122\u001b[0m                     X_train_clean,\n\u001b[1;32m    123\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[20], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[20], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_27\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    121\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    122\u001b[0m                     X_train_clean,\n\u001b[1;32m    123\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[23], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_27\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_30\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    122\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    123\u001b[0m                     X_train_clean,\n\u001b[1;32m    124\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[24], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[24], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_30\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024, 1))\n",
    "    \n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 10:20:26.587317: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 10:20:26.596910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731991826.608238    8612 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731991826.611354    8612 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 10:20:26.623154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731991828.218981    8612 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    122\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    123\u001b[0m                     X_train_clean,\n\u001b[1;32m    124\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[1], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024,))\n",
    "    \n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    122\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    123\u001b[0m                     X_train_clean,\n\u001b[1;32m    124\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[2], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024,))\n",
    "    \n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    122\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    123\u001b[0m                     X_train_clean,\n\u001b[1;32m    124\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[5], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "    \n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "        \n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "        \n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "    \n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "    \n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "    \n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "    \n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  # Spatial domain (shape (1024,))\n",
    "    \n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  # Temporal domain (shape (201,))\n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    126\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    127\u001b[0m                     X_train_clean,\n\u001b[1;32m    128\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     72\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input shapes: x_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    129\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    130\u001b[0m                     X_train_clean,\n\u001b[1;32m    131\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[7], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    129\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    130\u001b[0m                     X_train_clean,\n\u001b[1;32m    131\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Check if shapes are correct before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_18\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    129\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    130\u001b[0m                     X_train_clean,\n\u001b[1;32m    131\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[9], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_18\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_21\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    129\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    130\u001b[0m                     X_train_clean,\n\u001b[1;32m    131\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[10], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_21\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    129\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    130\u001b[0m                     X_train_clean,\n\u001b[1;32m    131\u001b[0m                     T_clean)\n",
      "Cell \u001b[0;32mIn[11], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_24\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from HDF5 file\n",
    "    initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "    # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "    # Spatial domain (shape (1024,))\n",
    "    x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "    # Temporal domain for clean data (shape (201,))\n",
    "    t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "    # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "    X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "    T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for clean data\n",
    "    print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "    print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for clean data\n",
    "    pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    print(\"Training on clean data...\")\n",
    "    \n",
    "    # Train PINN on clean data\n",
    "    train_pinn(pinn_model_clean,\n",
    "                X_train_clean,\n",
    "                T_clean)\n",
    "\n",
    "    # Visualize output for clean data\n",
    "    visualize_output(pinn_model_clean,\n",
    "                        X_train_clean,\n",
    "                        T_clean)\n",
    "\n",
    "        \n",
    "    print(\"Training on noisy data...\")\n",
    "    \n",
    "    # Prepare training data for noisy dataset\n",
    "    t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "    \n",
    "    X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "    # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "    T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "    \n",
    "    # Debugging: Print shapes to verify correctness for noisy data\n",
    "    print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "    print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "    \n",
    "    # Create PINN model for noisy data\n",
    "    pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "    \n",
    "    # Train PINN on noisy data\n",
    "    train_pinn(pinn_model_noisy,\n",
    "                X_train_noisy,\n",
    "                T_noisy)\n",
    "\n",
    "    # Visualize output for noisy data\n",
    "    visualize_output(pinn_model_noisy,\n",
    "                        X_train_noisy,\n",
    "                        T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_27\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    130\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    131\u001b[0m                  X_train_clean,\n\u001b[1;32m    132\u001b[0m                  T_clean)\n",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_27\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "   # Load data from HDF5 file\n",
    "   initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "   # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "   # Spatial domain (shape (1024,))\n",
    "   x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "   # Temporal domain for clean data (shape (201,))\n",
    "   t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "   # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "   X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "   T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for clean data\n",
    "   print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "   print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for clean data\n",
    "   pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   print(\"Training on clean data...\")\n",
    "   \n",
    "   # Train PINN on clean data\n",
    "   train_pinn(pinn_model_clean,\n",
    "               X_train_clean,\n",
    "               T_clean)\n",
    "\n",
    "   # Visualize output for clean data\n",
    "   visualize_output(pinn_model_clean,\n",
    "                    X_train_clean,\n",
    "                    T_clean)\n",
    "\n",
    "    \n",
    "   print(\"Training on noisy data...\")\n",
    "   \n",
    "   # Prepare training data for noisy dataset\n",
    "   t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "   \n",
    "   X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "   T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for noisy data\n",
    "   print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "   print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for noisy data\n",
    "   pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   # Train PINN on noisy data\n",
    "   train_pinn(pinn_model_noisy,\n",
    "              X_train_noisy,\n",
    "              T_noisy)\n",
    "\n",
    "   # Visualize output for noisy data\n",
    "   visualize_output(pinn_model_noisy,\n",
    "                    X_train_noisy,\n",
    "                    T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_30\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    130\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    131\u001b[0m                  X_train_clean,\n\u001b[1;32m    132\u001b[0m                  T_clean)\n",
      "Cell \u001b[0;32mIn[13], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_30\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "   # Load data from HDF5 file\n",
    "   initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "   # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "   # Spatial domain (shape (1024,))\n",
    "   x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "   # Temporal domain for clean data (shape (201,))\n",
    "   t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "   # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "   X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "   T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for clean data\n",
    "   print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "   print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for clean data\n",
    "   pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   print(\"Training on clean data...\")\n",
    "   \n",
    "   # Train PINN on clean data\n",
    "   train_pinn(pinn_model_clean,\n",
    "               X_train_clean,\n",
    "               T_clean)\n",
    "\n",
    "   # Visualize output for clean data\n",
    "   visualize_output(pinn_model_clean,\n",
    "                    X_train_clean,\n",
    "                    T_clean)\n",
    "\n",
    "        \n",
    "   print(\"Training on noisy data...\")\n",
    "   \n",
    "   # Prepare training data for noisy dataset\n",
    "   t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "   \n",
    "   X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "   T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for noisy data\n",
    "   print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "   print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for noisy data\n",
    "   pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   # Train PINN on noisy data\n",
    "   train_pinn(pinn_model_noisy,\n",
    "               X_train_noisy,\n",
    "               T_noisy)\n",
    "\n",
    "   # Visualize output for noisy data\n",
    "   visualize_output(pinn_model_noisy,\n",
    "                    X_train_noisy,\n",
    "                    T_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean shape: (205824, 2)\n",
      "T_clean shape: (205824, 1)\n",
      "Training on clean data...\n",
      "Training input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Physics loss input shapes - x_train: (205824, 2), t_train: (205824, 1)\n",
      "Before concatenation - x_train shape: (205824, 2), t_train shape: (205824, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_33\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on clean data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Train PINN on clean data\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mtrain_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn_model_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_train_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mT_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Visualize output for clean data\u001b[39;00m\n\u001b[1;32m    130\u001b[0m visualize_output(pinn_model_clean,\n\u001b[1;32m    131\u001b[0m                  X_train_clean,\n\u001b[1;32m    132\u001b[0m                  T_clean)\n",
      "Cell \u001b[0;32mIn[14], line 72\u001b[0m, in \u001b[0;36mtrain_pinn\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):  \u001b[38;5;66;03m# Adjust epochs as needed\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 72\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mphysics_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m, in \u001b[0;36mphysics_loss\u001b[0;34m(model, x_train, t_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore concatenation - x_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Calculate predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m u_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute gradients w.r.t. x and t\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_33\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (205824, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(205824, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from HDF5 file\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        initial_condition = f['0/initial_condition'][()]\n",
    "        boundary_condition = f['0/boundary_condition'][()]\n",
    "        clean_data = f['0/clean'][()]\n",
    "        noisy_data = f['0/noisy'][()]\n",
    "        du = f['0/du'][()]\n",
    "        epsilon = f['0/epsilon'][()]\n",
    "        u0 = f['0/u0'][()]\n",
    "        noise_level = f['0/noise_level'][()]\n",
    "        \n",
    "    return initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level\n",
    "\n",
    "# Define PINN model\n",
    "def create_pinn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(50, activation='tanh'))\n",
    "    model.add(layers.Dense(1))  # Output layer for solution\n",
    "    return model\n",
    "\n",
    "# Physics-informed loss function\n",
    "def physics_loss(model, x_train, t_train):\n",
    "    print(f\"Physics loss input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Ensure inputs are correctly shaped before concatenation\n",
    "    if x_train.shape[1] != 2 or t_train.shape[1] != 1:\n",
    "        raise ValueError(f\"Unexpected input shapes: x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    # Debugging: Check shapes before concatenation\n",
    "    print(f\"Before concatenation - x_train shape: {x_train.shape}, t_train shape: {t_train.shape}\")\n",
    "\n",
    "    # Calculate predictions\n",
    "    u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "\n",
    "    # Compute gradients w.r.t. x and t\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_train)\n",
    "        tape.watch(t_train)\n",
    "\n",
    "        u_pred = model(tf.concat([x_train, t_train], axis=1))\n",
    "        u_x = tape.gradient(u_pred, x_train)\n",
    "\n",
    "    u_t = tape.gradient(u_pred, t_train)\n",
    "\n",
    "    # Burgers' equation: u_t + u * u_x - nu * u_xx = 0\n",
    "    nu = epsilon  # Viscosity coefficient\n",
    "    u_xx = tape.gradient(u_x, x_train)\n",
    "\n",
    "    # Physics loss based on Burgers' equation\n",
    "    loss = tf.reduce_mean(tf.square(u_t + u_pred * u_x - nu * u_xx))\n",
    "\n",
    "    del tape  # Clean up\n",
    "    return loss\n",
    "\n",
    "# Training function\n",
    "def train_pinn(model, x_train, t_train):\n",
    "    print(f\"Training input shapes - x_train: {x_train.shape}, t_train: {t_train.shape}\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    for epoch in range(10000):  # Adjust epochs as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_loss(model, x_train, t_train)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 1000 == 0:  # Print every 1000 epochs\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_output(model, x_data, t_data):\n",
    "    print(f\"Visualizing output - x_data shape: {x_data.shape}, t_data shape: {t_data.shape}\")\n",
    "\n",
    "    u_pred = model(tf.concat([x_data, t_data], axis=1)).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(u_pred.reshape((t_data.shape[0], x_data.shape[0])), aspect='auto', extent=[0, 1, 0, 1])\n",
    "    plt.colorbar(label='u(x,t)')\n",
    "    plt.title('Predicted Solution of Burgers\\' Equation')\n",
    "    plt.xlabel('Spatial Coordinate (x)')\n",
    "    plt.ylabel('Temporal Coordinate (t)')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "   # Load data from HDF5 file\n",
    "   initial_condition, boundary_condition, clean_data, noisy_data, du, epsilon, u0, noise_level = load_data('/home/pes1ug22am100/Documents/Research and Experimentation/KINN Final/PINNdropSilence/simulation_data.h5')\n",
    "\n",
    "   # Prepare training data (spatial and temporal coordinates)\n",
    "    \n",
    "   # Spatial domain (shape (1024,))\n",
    "   x_train = np.linspace(0, 1, clean_data.shape[1])[:, None]  \n",
    "    \n",
    "   # Temporal domain for clean data (shape (201,))\n",
    "   t_train_clean = np.linspace(0, 1, clean_data.shape[0])[:, None]  \n",
    "    \n",
    "   # Create meshgrid for training data (combine spatial and temporal)\n",
    "    \n",
    "   X_train_clean = np.array(np.meshgrid(x_train.flatten(), t_train_clean.flatten())).T.reshape(-1, 2)  # Shape (n_samples_clean, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for clean data (ensure they are of shape (n_samples,))\n",
    "   T_clean = np.tile(t_train_clean.flatten(), (clean_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for clean data\n",
    "   print(\"X_train_clean shape:\", X_train_clean.shape)      # Should be (205824, 2)\n",
    "   print(\"T_clean shape:\", T_clean.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for clean data\n",
    "   pinn_model_clean = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   print(\"Training on clean data...\")\n",
    "   \n",
    "   # Train PINN on clean data\n",
    "   train_pinn(pinn_model_clean,\n",
    "               X_train_clean,\n",
    "               T_clean)\n",
    "\n",
    "   # Visualize output for clean data\n",
    "   visualize_output(pinn_model_clean,\n",
    "                    X_train_clean,\n",
    "                    T_clean)\n",
    "\n",
    "        \n",
    "   print(\"Training on noisy data...\")\n",
    "   \n",
    "   # Prepare training data for noisy dataset\n",
    "   t_train_noisy = np.linspace(0, 1, noisy_data.shape[0])[:, None]  # Temporal domain for noisy data (shape (201,))\n",
    "   \n",
    "   X_train_noisy = np.array(np.meshgrid(x_train.flatten(), t_train_noisy.flatten())).T.reshape(-1, 2)  # Shape (n_samples_noisy, 2)\n",
    "\n",
    "   # Prepare corresponding temporal inputs for noisy data (ensure they are of shape (n_samples,))\n",
    "   T_noisy = np.tile(t_train_noisy.flatten(), (noisy_data.shape[1],)).flatten()[:, None]   # Shape should be (205824,)\n",
    "   \n",
    "   # Debugging: Print shapes to verify correctness for noisy data\n",
    "   print(\"X_train_noisy shape:\", X_train_noisy.shape)      # Should be (205824, 2)\n",
    "   print(\"T_noisy shape:\", T_noisy.shape)                  # Should be (205824,)\n",
    "   \n",
    "   # Create PINN model for noisy data\n",
    "   pinn_model_noisy = create_pinn_model(input_shape=(2,))\n",
    "   \n",
    "   # Train PINN on noisy data\n",
    "   train_pinn(pinn_model_noisy,\n",
    "               X_train_noisy,\n",
    "               T_noisy)\n",
    "\n",
    "   # Visualize output for noisy data\n",
    "   visualize_output(pinn_model_noisy,\n",
    "                    X_train_noisy,\n",
    "                    T_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
