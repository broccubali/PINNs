{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee36854",
   "metadata": {
    "papermill": {
     "duration": 0.004781,
     "end_time": "2024-11-21T11:24:29.415643",
     "exception": false,
     "start_time": "2024-11-21T11:24:29.410862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Physics Informed Neural Networks**\n",
    "\n",
    "Physics-Informed Neural Networks (PINNs) are a class of machine learning models that integrate the physical laws governing a system, typically in the form of partial differential equations (PDEs), into the neural network's training process. This approach allows the network to learn solutions to PDEs without needing a large dataset of solution points. Instead, the PINN enforces the PDEs as constraints in the loss function, guiding the network to discover solutions that satisfy the underlying physics. This makes PINNs particularly useful for solving complex problems in fluid dynamics, heat transfer, and other fields where data may be sparse or hard to obtain. \n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "This notebook defines a simple PINN model using TensorFlow. The class `PINN` constructs a fully connected neural network with layers specified by `layers_dims`. Each layer uses the `tanh` activation function, except the output layer, which produces a single continuous value. The model is designed to take inputs (such as spatial and time coordinates) and return a prediction, which can be further trained to satisfy the given physical laws expressed as PDEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552c16ea",
   "metadata": {
    "_cell_guid": "1321b850-53a7-499a-9713-0c452e67d125",
    "_uuid": "0cb88dac-e382-406b-a687-6bc20ce7067b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:29.425275Z",
     "iopub.status.busy": "2024-11-21T11:24:29.424969Z",
     "iopub.status.idle": "2024-11-21T11:24:41.649192Z",
     "shell.execute_reply": "2024-11-21T11:24:41.648511Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.231308,
     "end_time": "2024-11-21T11:24:41.651103",
     "exception": false,
     "start_time": "2024-11-21T11:24:29.419795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import h5py\n",
    "\n",
    "\n",
    "class PINN(Model):\n",
    "    def __init__(self, layers_dims):\n",
    "        super(PINN, self).__init__()\n",
    "        self.network = tf.keras.Sequential()\n",
    "        for dim in layers_dims:\n",
    "            self.network.add(layers.Dense(dim, activation=\"tanh\"))\n",
    "        self.network.add(layers.Dense(1))  \n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.network(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace12b7",
   "metadata": {
    "papermill": {
     "duration": 0.003879,
     "end_time": "2024-11-21T11:24:41.659320",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.655441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Physics informed loss\n",
    "\n",
    "A function to compute the loss for training a Physics-Informed Neural Network (PINN) to solve a partial differential equation (PDE), while enforcing initial conditions, boundary conditions, and the PDE itself.\n",
    "- **Operations** : \n",
    "  1. **Gradient Calculation**: \n",
    "     - Computes the first and second derivatives of the model's output (`u`) with respect to spatial (`x`) and time (`t`) using `tf.GradientTape`.\n",
    "  2. **PDE Residual**: \n",
    "     - Calculates the residual of the PDE, involving terms like `u_t`, `u_x`, and `u_xx`, which should ideally be zero for a valid solution.\n",
    "\n",
    "- **Loss Components**:\n",
    "  - **Initial Condition Loss**: \n",
    "    - Measures the difference between the model's predicted solution at `t=0` and the given `initial_condition`.\n",
    "  - **Periodic Boundary Condition Loss**: \n",
    "    - Enforces periodic boundary conditions by ensuring the solution and its spatial derivative are the same at the boundary points (`x_min` and `x_max`).\n",
    "  - **Residual Loss**: \n",
    "    - Penalizes deviations from the PDE's residual to ensure the model satisfies the physical equation.\n",
    "\n",
    "- **Output**:\n",
    "  - Returns the total loss, which is the sum of the initial condition loss, periodic boundary loss, and residual loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4579e96d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:41.669592Z",
     "iopub.status.busy": "2024-11-21T11:24:41.669097Z",
     "iopub.status.idle": "2024-11-21T11:24:41.675838Z",
     "shell.execute_reply": "2024-11-21T11:24:41.675124Z"
    },
    "papermill": {
     "duration": 0.013066,
     "end_time": "2024-11-21T11:24:41.677344",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.664278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def physics_informed_loss(\n",
    "    model, x, t, initial_condition, boundary_condition, du, epsilon\n",
    "):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([x, t])\n",
    "        epsilon_tensor = tf.fill(x.shape,  tf.constant(epsilon, dtype=tf.float32))\n",
    "        u = model(tf.concat([x, t, epsilon_tensor], axis=1))\n",
    "\n",
    "        u_t = tape.gradient(u, t)\n",
    "        u_x = tape.gradient(u, x)\n",
    "        u_xx = tape.gradient(u_x, x)\n",
    "\n",
    "    residual = u_t + u * u_x - epsilon * u_xx\n",
    "\n",
    "    # Initial condition loss\n",
    "    initial_loss = tf.reduce_mean(\n",
    "        tf.square(u[tf.equal(t, tf.reduce_min(t))] - initial_condition)\n",
    "    )\n",
    "\n",
    "    # Periodic boundary condition loss\n",
    "    periodic_loss = tf.reduce_mean(\n",
    "        tf.square(u[tf.equal(x, tf.reduce_min(x))] - u[tf.equal(x, tf.reduce_max(x))])\n",
    "    ) + tf.reduce_mean(\n",
    "        tf.square(\n",
    "            u_x[tf.equal(x, tf.reduce_min(x))] - u_x[tf.equal(x, tf.reduce_max(x))]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Residual loss\n",
    "    residual_loss = tf.reduce_mean(tf.square(residual))\n",
    "\n",
    "    return initial_loss + periodic_loss + residual_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d4026",
   "metadata": {
    "papermill": {
     "duration": 0.003778,
     "end_time": "2024-11-21T11:24:41.685060",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.681282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop\n",
    "\n",
    "\n",
    "- **Operations**:\n",
    "  1. **Grid Creation**: \n",
    "     - Creates a mesh grid of spatial (`x_grid`) and time (`t_grid`) values, then flattens them into 1D arrays (`x_flat` and `t_flat`).\n",
    "  2. **Optimizer Setup**: \n",
    "     - Uses the Adam optimizer with the specified `learning_rate` to minimize the loss.\n",
    "  3. **Training Loop**: \n",
    "     - For each epoch, computes the loss using `physics_informed_loss` and updates the model parameters by computing gradients and applying them through the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d205eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:41.693878Z",
     "iopub.status.busy": "2024-11-21T11:24:41.693641Z",
     "iopub.status.idle": "2024-11-21T11:24:41.699037Z",
     "shell.execute_reply": "2024-11-21T11:24:41.698281Z"
    },
    "papermill": {
     "duration": 0.011602,
     "end_time": "2024-11-21T11:24:41.700527",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.688925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    x,\n",
    "    t,\n",
    "    initial_condition,\n",
    "    boundary_condition,\n",
    "    du,\n",
    "    epsilon,\n",
    "    epochs,\n",
    "    learning_rate,\n",
    "):\n",
    "    x_grid, t_grid = tf.meshgrid(x[:, 0], t[:, 0])  \n",
    "    x_flat = tf.reshape(x_grid, [-1, 1])  \n",
    "    t_flat = tf.reshape(t_grid, [-1, 1]) \n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = physics_informed_loss(\n",
    "                model,\n",
    "                x_flat,\n",
    "                t_flat,\n",
    "                initial_condition,\n",
    "                boundary_condition,\n",
    "                du,\n",
    "                epsilon,\n",
    "            )\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4346a4",
   "metadata": {
    "papermill": {
     "duration": 0.003788,
     "end_time": "2024-11-21T11:24:41.708287",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.704499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "\n",
    "Opens the HDF5 file and retrieves:\n",
    "- `initial_condition` and `boundary_condition`: Initial and boundary values for the solution, clean or noisy depending on input.\n",
    "- `clean_data`: The ground truth solution data.\n",
    "- `du`: Derivative of the solution.\n",
    "- `epsilon`: A parameter (e.g., diffusion coefficient).\n",
    "- `u0`: Initial value of the solution.\n",
    "- `x` and `t`: Spatial and time coordinates.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59561bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:41.717270Z",
     "iopub.status.busy": "2024-11-21T11:24:41.717033Z",
     "iopub.status.idle": "2024-11-21T11:24:41.721667Z",
     "shell.execute_reply": "2024-11-21T11:24:41.720920Z"
    },
    "papermill": {
     "duration": 0.010897,
     "end_time": "2024-11-21T11:24:41.723160",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.712263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, type):\n",
    "    with h5py.File(file_name, \"r\") as f:\n",
    "        initial_condition = f[f\"0/initial_condition_{type}\"][:]\n",
    "        boundary_condition = f[f\"0/boundary_condition_{type}\"][:]\n",
    "        clean_data = f[\"0/clean\"][:]\n",
    "        du = f[\"0/du\"][()]\n",
    "        epsilon = f[\"0/epsilon\"][()]\n",
    "        u0 = f[\"0/u0\"][()]\n",
    "        x = f[\"coords/x-coordinates\"][:]\n",
    "        t = f[\"coords/t-coordinates\"][:-1]\n",
    "    return (\n",
    "        initial_condition,\n",
    "        boundary_condition,\n",
    "        clean_data,\n",
    "        du,\n",
    "        epsilon,\n",
    "        u0,\n",
    "        x,\n",
    "        t,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e320a29",
   "metadata": {
    "papermill": {
     "duration": 0.003784,
     "end_time": "2024-11-21T11:24:41.730843",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.727059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Setup\n",
    "\n",
    "This code loads the simulation data from an HDF5 file and prepares it for training a Physics-Informed Neural Network (PINN) to solve the noisy version of the Burgers' equation.\n",
    "\n",
    "  1. Load data from the file `simulation_data.h5` using the `load_data` function (loading initial conditions, boundary conditions, solution data, and other parameters).\n",
    "  2. Convert the `x` and `t` coordinate arrays to TensorFlow tensors and reshapes them as column vectors.\n",
    "  3. Convert `initial_condition` and `boundary_condition` to TensorFlow tensors.\n",
    "  \n",
    "- **Model Setup**: \n",
    "  - The PINN architecture is initialized with 3 hidden layers, each with 50 neurons (`layers_dims = [50, 50, 50]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3df704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:41.740150Z",
     "iopub.status.busy": "2024-11-21T11:24:41.739571Z",
     "iopub.status.idle": "2024-11-21T11:24:42.661152Z",
     "shell.execute_reply": "2024-11-21T11:24:42.660503Z"
    },
    "papermill": {
     "duration": 0.928274,
     "end_time": "2024-11-21T11:24:42.663129",
     "exception": false,
     "start_time": "2024-11-21T11:24:41.734855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_name = (\n",
    "    \"/kaggle/input/burgers-noisy/simulation_data.h5\"  # Replace with your data file\n",
    ")\n",
    "initial_condition, boundary_condition, clean_data, du, epsilon, u0, x, t = load_data(\n",
    "    file_name, \"noisy\"\n",
    ")\n",
    "\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)[:, None]  # x-coordinates as column vector\n",
    "t = tf.convert_to_tensor(t, dtype=tf.float32)[:, None]  # t-coordinates as column vector\n",
    "initial_condition = tf.convert_to_tensor(initial_condition, dtype=tf.float32)\n",
    "boundary_condition = tf.convert_to_tensor(boundary_condition, dtype=tf.float32)\n",
    "\n",
    "layers_dims = [50, 50, 50]\n",
    "epochs = 10000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = PINN(layers_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b8f55",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2024-11-21T11:24:42.671286",
     "exception": false,
     "start_time": "2024-11-21T11:24:42.667379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b266b79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:24:42.680521Z",
     "iopub.status.busy": "2024-11-21T11:24:42.680247Z",
     "iopub.status.idle": "2024-11-21T11:42:30.318320Z",
     "shell.execute_reply": "2024-11-21T11:42:30.317419Z"
    },
    "papermill": {
     "duration": 1067.644932,
     "end_time": "2024-11-21T11:42:30.320329",
     "exception": false,
     "start_time": "2024-11-21T11:24:42.675397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.494818\n",
      "Epoch 100, Loss: 0.554695\n",
      "Epoch 200, Loss: 0.329819\n",
      "Epoch 300, Loss: 0.261835\n",
      "Epoch 400, Loss: 0.251033\n",
      "Epoch 500, Loss: 0.243114\n",
      "Epoch 600, Loss: 0.235674\n",
      "Epoch 700, Loss: 0.225637\n",
      "Epoch 800, Loss: 0.210556\n",
      "Epoch 900, Loss: 0.192006\n",
      "Epoch 1000, Loss: 0.179609\n",
      "Epoch 1100, Loss: 0.172866\n",
      "Epoch 1200, Loss: 0.168310\n",
      "Epoch 1300, Loss: 0.166577\n",
      "Epoch 1400, Loss: 0.165576\n",
      "Epoch 1500, Loss: 0.164757\n",
      "Epoch 1600, Loss: 0.165785\n",
      "Epoch 1700, Loss: 0.163406\n",
      "Epoch 1800, Loss: 0.162896\n",
      "Epoch 1900, Loss: 0.162403\n",
      "Epoch 2000, Loss: 0.161876\n",
      "Epoch 2100, Loss: 0.161491\n",
      "Epoch 2200, Loss: 0.161090\n",
      "Epoch 2300, Loss: 0.160681\n",
      "Epoch 2400, Loss: 0.160311\n",
      "Epoch 2500, Loss: 0.159940\n",
      "Epoch 2600, Loss: 0.159551\n",
      "Epoch 2700, Loss: 0.159180\n",
      "Epoch 2800, Loss: 0.158714\n",
      "Epoch 2900, Loss: 0.158261\n",
      "Epoch 3000, Loss: 0.157784\n",
      "Epoch 3100, Loss: 0.157315\n",
      "Epoch 3200, Loss: 0.156725\n",
      "Epoch 3300, Loss: 0.156198\n",
      "Epoch 3400, Loss: 0.155630\n",
      "Epoch 3500, Loss: 0.155062\n",
      "Epoch 3600, Loss: 0.154460\n",
      "Epoch 3700, Loss: 0.153882\n",
      "Epoch 3800, Loss: 0.153300\n",
      "Epoch 3900, Loss: 0.152748\n",
      "Epoch 4000, Loss: 0.153587\n",
      "Epoch 4100, Loss: 0.151909\n",
      "Epoch 4200, Loss: 0.151253\n",
      "Epoch 4300, Loss: 0.150543\n",
      "Epoch 4400, Loss: 0.151866\n",
      "Epoch 4500, Loss: 0.149415\n",
      "Epoch 4600, Loss: 0.148859\n",
      "Epoch 4700, Loss: 0.149837\n",
      "Epoch 4800, Loss: 0.152071\n",
      "Epoch 4900, Loss: 0.147276\n",
      "Epoch 5000, Loss: 0.146805\n",
      "Epoch 5100, Loss: 0.146445\n",
      "Epoch 5200, Loss: 0.146188\n",
      "Epoch 5300, Loss: 0.145662\n",
      "Epoch 5400, Loss: 0.145928\n",
      "Epoch 5500, Loss: 0.144529\n",
      "Epoch 5600, Loss: 0.144105\n",
      "Epoch 5700, Loss: 0.143683\n",
      "Epoch 5800, Loss: 0.143281\n",
      "Epoch 5900, Loss: 0.143836\n",
      "Epoch 6000, Loss: 0.142540\n",
      "Epoch 6100, Loss: 0.142439\n",
      "Epoch 6200, Loss: 0.141555\n",
      "Epoch 6300, Loss: 0.141112\n",
      "Epoch 6400, Loss: 0.140664\n",
      "Epoch 6500, Loss: 0.140288\n",
      "Epoch 6600, Loss: 0.139788\n",
      "Epoch 6700, Loss: 0.140147\n",
      "Epoch 6800, Loss: 0.139137\n",
      "Epoch 6900, Loss: 0.138377\n",
      "Epoch 7000, Loss: 0.137921\n",
      "Epoch 7100, Loss: 0.137462\n",
      "Epoch 7200, Loss: 0.137241\n",
      "Epoch 7300, Loss: 0.136679\n",
      "Epoch 7400, Loss: 0.136104\n",
      "Epoch 7500, Loss: 0.136187\n",
      "Epoch 7600, Loss: 0.135338\n",
      "Epoch 7700, Loss: 0.134896\n",
      "Epoch 7800, Loss: 0.134627\n",
      "Epoch 7900, Loss: 0.134114\n",
      "Epoch 8000, Loss: 0.133850\n",
      "Epoch 8100, Loss: 0.133421\n",
      "Epoch 8200, Loss: 0.133079\n",
      "Epoch 8300, Loss: 0.132694\n",
      "Epoch 8400, Loss: 0.132721\n",
      "Epoch 8500, Loss: 0.131986\n",
      "Epoch 8600, Loss: 0.131680\n",
      "Epoch 8700, Loss: 0.131279\n",
      "Epoch 8800, Loss: 0.131484\n",
      "Epoch 8900, Loss: 0.130386\n",
      "Epoch 9000, Loss: 0.129773\n",
      "Epoch 9100, Loss: 0.129355\n",
      "Epoch 9200, Loss: 0.128692\n",
      "Epoch 9300, Loss: 0.128221\n",
      "Epoch 9400, Loss: 0.127765\n",
      "Epoch 9500, Loss: 0.127611\n",
      "Epoch 9600, Loss: 0.129514\n",
      "Epoch 9700, Loss: 0.126884\n",
      "Epoch 9800, Loss: 0.128018\n",
      "Epoch 9900, Loss: 0.125899\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model,\n",
    "    x,\n",
    "    t,\n",
    "    initial_condition,\n",
    "    boundary_condition,\n",
    "    du,\n",
    "    epsilon,\n",
    "    epochs,\n",
    "    learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2378bf4",
   "metadata": {
    "papermill": {
     "duration": 0.007866,
     "end_time": "2024-11-21T11:42:30.336803",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.328937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction\n",
    "\n",
    "#### Boundary Condition enforcement\n",
    "\n",
    "This function enforces periodic boundary conditions on the solution array `u`.\n",
    "\n",
    "  - Uses `tf.tensor_scatter_nd_update` to swap the values at the first and last indices of the solution array `u`, ensuring periodicity.\n",
    "\n",
    "- Returns the modified solution array `u` with periodic boundary conditions applied, preserving the original shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a8a842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:30.353971Z",
     "iopub.status.busy": "2024-11-21T11:42:30.353718Z",
     "iopub.status.idle": "2024-11-21T11:42:30.358348Z",
     "shell.execute_reply": "2024-11-21T11:42:30.357695Z"
    },
    "papermill": {
     "duration": 0.015147,
     "end_time": "2024-11-21T11:42:30.359988",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.344841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_periodic_bc(u, boundary_condition):\n",
    "    \"\"\"\n",
    "    Enforce periodic boundary conditions on the solution.\n",
    "    Args:\n",
    "        u: Solution array at a given time step (tensor).\n",
    "        boundary_condition: Precomputed boundary values (not directly used here).\n",
    "    Returns:\n",
    "        Solution array with periodic boundary applied (same shape as input).\n",
    "    \"\"\"\n",
    "    u = tf.tensor_scatter_nd_update(\n",
    "        u,\n",
    "        indices=[[0], [-1]], \n",
    "        updates=[u[-1], u[0]],  \n",
    "    )\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c53319",
   "metadata": {
    "papermill": {
     "duration": 0.007693,
     "end_time": "2024-11-21T11:42:30.375730",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.368037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Iterative time step prediction\n",
    "\n",
    "  1. Initialize the solution with the `initial_condition` and store the first prediction.\n",
    "  2. For each time step, concatenates the current spatial coordinates, solution, and `epsilon` to form the input for the model.\n",
    "  3. The model predicts the solution at the next time step (`u_next`), and periodic boundary conditions are applied using the `apply_periodic_bc` function.\n",
    "  4. Appends each new prediction to the list `all_predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c15abd",
   "metadata": {
    "_cell_guid": "bfc8be1b-65b4-4df6-95ab-c6e43db08d75",
    "_uuid": "e3aa41a2-99d5-493f-b83c-de785d11a76c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:30.392849Z",
     "iopub.status.busy": "2024-11-21T11:42:30.392625Z",
     "iopub.status.idle": "2024-11-21T11:42:30.398276Z",
     "shell.execute_reply": "2024-11-21T11:42:30.397526Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01608,
     "end_time": "2024-11-21T11:42:30.399849",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.383769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_solution_iterative(\n",
    "    model, x, initial_condition, boundary_condition, epsilon, n_steps\n",
    "):\n",
    "    \"\"\"\n",
    "    Iteratively predict the solution over time.\n",
    "    Args:\n",
    "        model: Trained PINN model.\n",
    "        x: Spatial coordinates as a tensor.\n",
    "        initial_condition: Initial condition at t=0.\n",
    "        boundary_condition: Boundary conditions (periodic).\n",
    "        epsilon: Diffusion parameter.\n",
    "        n_steps: Number of time steps to predict.\n",
    "    Returns:\n",
    "        Array of predictions at each time step.\n",
    "    \"\"\"\n",
    "    u = tf.convert_to_tensor(initial_condition, dtype=tf.float32)[:, None] \n",
    "    all_predictions = [u.numpy().reshape(-1)]\n",
    "    print(u.shape)\n",
    "    for _ in range(n_steps):\n",
    "        epsilon_tensor = tf.fill(\n",
    "            x.shape, tf.constant(epsilon, dtype=tf.float32)\n",
    "        )  \n",
    "        u_input = tf.concat([x, u], axis=1) \n",
    "        u_input = tf.concat(\n",
    "            [u_input, epsilon_tensor], axis=1\n",
    "        )  \n",
    "        u_next = model(u_input)[:, 0]  \n",
    "        u_next = apply_periodic_bc(u_next, boundary_condition)\n",
    "\n",
    "        all_predictions.append(u_next.numpy())\n",
    "        u = u_next[:, None]\n",
    "    return np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63031d5e",
   "metadata": {
    "papermill": {
     "duration": 0.007648,
     "end_time": "2024-11-21T11:42:30.415744",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.408096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Predictions \n",
    "\n",
    "Prepare the data and make predictions over loaded clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef21af80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:30.432715Z",
     "iopub.status.busy": "2024-11-21T11:42:30.432452Z",
     "iopub.status.idle": "2024-11-21T11:42:31.637858Z",
     "shell.execute_reply": "2024-11-21T11:42:31.636771Z"
    },
    "papermill": {
     "duration": 1.215811,
     "end_time": "2024-11-21T11:42:31.639642",
     "exception": false,
     "start_time": "2024-11-21T11:42:30.423831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n",
      "Predicted solution shape: (201, 1024)\n"
     ]
    }
   ],
   "source": [
    "initial_condition, boundary_condition, clean_data, du, epsilon, u0, x, t = load_data(\n",
    "    file_name, \"clean\"\n",
    ")\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)[:, None]  \n",
    "t = tf.convert_to_tensor(t, dtype=tf.float32)[:, None]  \n",
    "initial_condition = tf.convert_to_tensor(initial_condition, dtype=tf.float32)\n",
    "boundary_condition = tf.convert_to_tensor(boundary_condition, dtype=tf.float32)\n",
    "n_steps = 200\n",
    "predicted_solution = predict_solution_iterative(\n",
    "    model,\n",
    "    x=x,\n",
    "    initial_condition=initial_condition,\n",
    "    boundary_condition=boundary_condition,\n",
    "    epsilon=epsilon,\n",
    "    n_steps=n_steps,\n",
    ")\n",
    "\n",
    "print(\"Predicted solution shape:\", predicted_solution.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d5523",
   "metadata": {
    "papermill": {
     "duration": 0.008009,
     "end_time": "2024-11-21T11:42:31.656064",
     "exception": false,
     "start_time": "2024-11-21T11:42:31.648055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualisation of Solution\n",
    "\n",
    "  1. For each time step, it plots the spatial coordinates (`xcrd`) versus the solution at that step and stores the plot in `ims` for animation.\n",
    "  2. Uses `ArtistAnimation` to create the animation from the collected frames.\n",
    "  \n",
    "  3. Saves the animation as a GIF using `PillowWriter` with a frame rate of 15 fps, and stores it at the specified `path`. The function also closes the figure after saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6311ba3e",
   "metadata": {
    "_cell_guid": "cc034f19-6d99-4a0a-a8cd-a2a8ae4d2235",
    "_uuid": "e55ac594-e743-4f0a-ad60-018012cd0eeb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:31.673748Z",
     "iopub.status.busy": "2024-11-21T11:42:31.673038Z",
     "iopub.status.idle": "2024-11-21T11:42:44.824633Z",
     "shell.execute_reply": "2024-11-21T11:42:44.823649Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13.16244,
     "end_time": "2024-11-21T11:42:44.826669",
     "exception": false,
     "start_time": "2024-11-21T11:42:31.664229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:00<00:00, 353.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def visualize_burgers(xcrd, data, path):\n",
    "    \"\"\"\n",
    "    This function animates the Burgers equation\n",
    "\n",
    "    Args:\n",
    "    path : path to the desired file\n",
    "    param: PDE parameter of the data shard to be visualized\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        if i == 0:\n",
    "            im = ax.plot(xcrd, data[i].squeeze(), animated=True, color=\"blue\")\n",
    "        else:\n",
    "            im = ax.plot(\n",
    "                xcrd, data[i].squeeze(), animated=True, color=\"blue\"\n",
    "            ) \n",
    "        ims.append([im[0]])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "\n",
    "    writer = animation.PillowWriter(fps=15, bitrate=1800)\n",
    "    ani.save(path, writer=writer)\n",
    "    plt.close(fig)\n",
    "    \n",
    "visualize_burgers(x, predicted_solution, \"noisy_trained_predicted_solution.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea152cd9",
   "metadata": {
    "papermill": {
     "duration": 0.008283,
     "end_time": "2024-11-21T11:42:44.843803",
     "exception": false,
     "start_time": "2024-11-21T11:42:44.835520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Clean\n",
    "\n",
    "Training over clean data for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b60c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:44.861816Z",
     "iopub.status.busy": "2024-11-21T11:42:44.861556Z",
     "iopub.status.idle": "2024-11-21T11:42:44.897994Z",
     "shell.execute_reply": "2024-11-21T11:42:44.897370Z"
    },
    "papermill": {
     "duration": 0.047287,
     "end_time": "2024-11-21T11:42:44.899604",
     "exception": false,
     "start_time": "2024-11-21T11:42:44.852317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = (\n",
    "    \"/kaggle/input/burgers-noisy/simulation_data.h5\"  \n",
    ")\n",
    "initial_condition, boundary_condition, clean_data, du, epsilon, u0, x, t = load_data(\n",
    "    file_name, \"clean\"\n",
    ")\n",
    "\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)[:, None] \n",
    "t = tf.convert_to_tensor(t, dtype=tf.float32)[:, None]  \n",
    "initial_condition = tf.convert_to_tensor(initial_condition, dtype=tf.float32)\n",
    "boundary_condition = tf.convert_to_tensor(boundary_condition, dtype=tf.float32)\n",
    "\n",
    "layers_dims = [50, 50, 50]\n",
    "epochs = 10000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = PINN(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cde26a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T11:42:44.917394Z",
     "iopub.status.busy": "2024-11-21T11:42:44.917120Z",
     "iopub.status.idle": "2024-11-21T12:00:32.397741Z",
     "shell.execute_reply": "2024-11-21T12:00:32.396698Z"
    },
    "papermill": {
     "duration": 1067.491943,
     "end_time": "2024-11-21T12:00:32.399953",
     "exception": false,
     "start_time": "2024-11-21T11:42:44.908010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.800827\n",
      "Epoch 100, Loss: 0.454979\n",
      "Epoch 200, Loss: 0.179035\n",
      "Epoch 300, Loss: 0.167613\n",
      "Epoch 400, Loss: 0.161234\n",
      "Epoch 500, Loss: 0.153584\n",
      "Epoch 600, Loss: 0.138297\n",
      "Epoch 700, Loss: 0.115942\n",
      "Epoch 800, Loss: 0.096874\n",
      "Epoch 900, Loss: 0.090514\n",
      "Epoch 1000, Loss: 0.083550\n",
      "Epoch 1100, Loss: 0.080961\n",
      "Epoch 1200, Loss: 0.077984\n",
      "Epoch 1300, Loss: 0.075869\n",
      "Epoch 1400, Loss: 0.073421\n",
      "Epoch 1500, Loss: 0.071164\n",
      "Epoch 1600, Loss: 0.069516\n",
      "Epoch 1700, Loss: 0.069805\n",
      "Epoch 1800, Loss: 0.068203\n",
      "Epoch 1900, Loss: 0.066629\n",
      "Epoch 2000, Loss: 0.065586\n",
      "Epoch 2100, Loss: 0.064821\n",
      "Epoch 2200, Loss: 0.064292\n",
      "Epoch 2300, Loss: 0.063304\n",
      "Epoch 2400, Loss: 0.062630\n",
      "Epoch 2500, Loss: 0.064358\n",
      "Epoch 2600, Loss: 0.061491\n",
      "Epoch 2700, Loss: 0.060974\n",
      "Epoch 2800, Loss: 0.060545\n",
      "Epoch 2900, Loss: 0.060758\n",
      "Epoch 3000, Loss: 0.063131\n",
      "Epoch 3100, Loss: 0.059417\n",
      "Epoch 3200, Loss: 0.059131\n",
      "Epoch 3300, Loss: 0.058837\n",
      "Epoch 3400, Loss: 0.058589\n",
      "Epoch 3500, Loss: 0.058327\n",
      "Epoch 3600, Loss: 0.058077\n",
      "Epoch 3700, Loss: 0.057844\n",
      "Epoch 3800, Loss: 0.057606\n",
      "Epoch 3900, Loss: 0.057710\n",
      "Epoch 4000, Loss: 0.057573\n",
      "Epoch 4100, Loss: 0.057272\n",
      "Epoch 4200, Loss: 0.056339\n",
      "Epoch 4300, Loss: 0.055984\n",
      "Epoch 4400, Loss: 0.055617\n",
      "Epoch 4500, Loss: 0.055284\n",
      "Epoch 4600, Loss: 0.055252\n",
      "Epoch 4700, Loss: 0.054316\n",
      "Epoch 4800, Loss: 0.053845\n",
      "Epoch 4900, Loss: 0.053375\n",
      "Epoch 5000, Loss: 0.052839\n",
      "Epoch 5100, Loss: 0.052522\n",
      "Epoch 5200, Loss: 0.051754\n",
      "Epoch 5300, Loss: 0.051624\n",
      "Epoch 5400, Loss: 0.050658\n",
      "Epoch 5500, Loss: 0.050144\n",
      "Epoch 5600, Loss: 0.049658\n",
      "Epoch 5700, Loss: 0.049386\n",
      "Epoch 5800, Loss: 0.049009\n",
      "Epoch 5900, Loss: 0.048541\n",
      "Epoch 6000, Loss: 0.047880\n",
      "Epoch 6100, Loss: 0.047468\n",
      "Epoch 6200, Loss: 0.047055\n",
      "Epoch 6300, Loss: 0.046628\n",
      "Epoch 6400, Loss: 0.046213\n",
      "Epoch 6500, Loss: 0.045777\n",
      "Epoch 6600, Loss: 0.045358\n",
      "Epoch 6700, Loss: 0.045259\n",
      "Epoch 6800, Loss: 0.044803\n",
      "Epoch 6900, Loss: 0.048584\n",
      "Epoch 7000, Loss: 0.043668\n",
      "Epoch 7100, Loss: 0.043300\n",
      "Epoch 7200, Loss: 0.042874\n",
      "Epoch 7300, Loss: 0.042514\n",
      "Epoch 7400, Loss: 0.042103\n",
      "Epoch 7500, Loss: 0.041863\n",
      "Epoch 7600, Loss: 0.041417\n",
      "Epoch 7700, Loss: 0.041195\n",
      "Epoch 7800, Loss: 0.040741\n",
      "Epoch 7900, Loss: 0.040488\n",
      "Epoch 8000, Loss: 0.040084\n",
      "Epoch 8100, Loss: 0.039809\n",
      "Epoch 8200, Loss: 0.039317\n",
      "Epoch 8300, Loss: 0.038992\n",
      "Epoch 8400, Loss: 0.038500\n",
      "Epoch 8500, Loss: 0.038258\n",
      "Epoch 8600, Loss: 0.037572\n",
      "Epoch 8700, Loss: 0.037531\n",
      "Epoch 8800, Loss: 0.036598\n",
      "Epoch 8900, Loss: 0.035996\n",
      "Epoch 9000, Loss: 0.035328\n",
      "Epoch 9100, Loss: 0.034679\n",
      "Epoch 9200, Loss: 0.034155\n",
      "Epoch 9300, Loss: 0.033326\n",
      "Epoch 9400, Loss: 0.032680\n",
      "Epoch 9500, Loss: 0.032483\n",
      "Epoch 9600, Loss: 0.031377\n",
      "Epoch 9700, Loss: 0.030776\n",
      "Epoch 9800, Loss: 0.030190\n",
      "Epoch 9900, Loss: 0.029643\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model,\n",
    "    x,\n",
    "    t,\n",
    "    initial_condition,\n",
    "    boundary_condition,\n",
    "    du,\n",
    "    epsilon,\n",
    "    epochs,\n",
    "    learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c1adb",
   "metadata": {
    "papermill": {
     "duration": 0.013145,
     "end_time": "2024-11-21T12:00:32.426564",
     "exception": false,
     "start_time": "2024-11-21T12:00:32.413419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Prediction over clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1838725f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T12:00:32.452914Z",
     "iopub.status.busy": "2024-11-21T12:00:32.452629Z",
     "iopub.status.idle": "2024-11-21T12:00:33.577171Z",
     "shell.execute_reply": "2024-11-21T12:00:33.576274Z"
    },
    "papermill": {
     "duration": 1.139864,
     "end_time": "2024-11-21T12:00:33.578909",
     "exception": false,
     "start_time": "2024-11-21T12:00:32.439045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n",
      "Predicted solution shape: (201, 1024)\n"
     ]
    }
   ],
   "source": [
    "initial_condition, boundary_condition, clean_data, du, epsilon, u0, x, t = load_data(\n",
    "    file_name, \"clean\"\n",
    ")\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)[:, None]  \n",
    "t = tf.convert_to_tensor(t, dtype=tf.float32)[:, None]  \n",
    "initial_condition = tf.convert_to_tensor(initial_condition, dtype=tf.float32)\n",
    "boundary_condition = tf.convert_to_tensor(boundary_condition, dtype=tf.float32)\n",
    "n_steps = 200\n",
    "predicted_solution = predict_solution_iterative(\n",
    "    model,\n",
    "    x=x,\n",
    "    initial_condition=initial_condition,\n",
    "    boundary_condition=boundary_condition,\n",
    "    epsilon=epsilon,\n",
    "    n_steps=n_steps,\n",
    ")\n",
    "\n",
    "print(\"Predicted solution shape:\", predicted_solution.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066c446",
   "metadata": {
    "papermill": {
     "duration": 0.015073,
     "end_time": "2024-11-21T12:00:33.607932",
     "exception": false,
     "start_time": "2024-11-21T12:00:33.592859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00059620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T12:00:33.637973Z",
     "iopub.status.busy": "2024-11-21T12:00:33.637415Z",
     "iopub.status.idle": "2024-11-21T12:00:45.720583Z",
     "shell.execute_reply": "2024-11-21T12:00:45.719843Z"
    },
    "papermill": {
     "duration": 12.100491,
     "end_time": "2024-11-21T12:00:45.722467",
     "exception": false,
     "start_time": "2024-11-21T12:00:33.621976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:00<00:00, 256.87it/s]\n"
     ]
    }
   ],
   "source": [
    "visualize_burgers(x, predicted_solution, \"clean_trained_predicted_solution.gif\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6074846,
     "sourceId": 9943646,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2181.437096,
   "end_time": "2024-11-21T12:00:48.351431",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-21T11:24:26.914335",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
