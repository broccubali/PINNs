{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov Arnold Networks\n",
    "\n",
    "### Kolmogorov-Arnold Networks (KANs): Overview  \n",
    "- **Theoretical Foundation**: Based on the Kolmogorov-Arnold representation theorem, which states that any multivariate continuous function can be expressed as a sum of univariate functions, allowing for a systematic decomposition of complex functions.  \n",
    "- **Architecture**: Decomposes high-dimensional mappings into a series of simpler one-dimensional functions, enabling efficient and accurate approximation of intricate dependencies in high-dimensional problems.  \n",
    "- **Applications**: Particularly useful in fields requiring complex function approximations, such as machine learning, physics, and computational mathematics.\n",
    "\n",
    "### KANs for Noise Removal in Partial Differential Equations (PDEs)  \n",
    "- **Denoising Mechanism**: KANs excel at separating structured signals from stochastic noise by learning the underlying deterministic relationships within the data governed by PDEs.  \n",
    "- **Training Process**: Trains to approximate noiseless PDE solutions by leveraging the network's bias towards representing smooth, well-structured functions.  \n",
    "- **Advantage**: Provides robust and efficient recovery of clean PDE solutions from noisy datasets, combining theoretical rigor with practical performance.  \n",
    "- **Practical Benefit**: Enhances the accuracy and reliability of numerical solutions for PDEs in scenarios where data is corrupted by noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "This implementation of KAN has been taken from https://github.com/Blealtan/efficient-kan. \n",
    "\n",
    "This code defines a **Kolmogorov-Arnold Network (KAN) Linear Layer** in PyTorch. It is designed to efficiently model complex relationships by combining linear transformations and B-spline interpolation, as informed by the Kolmogorov-Arnold representation theorem.\n",
    "\n",
    "###  Components:\n",
    "1. **Initialization and Grid Setup**:\n",
    "   - The grid represents the domain over which splines are interpolated. It is extended by the spline order to ensure smooth boundary conditions.\n",
    "   - Parameters for the layer include base weights (`base_weight`) for linear transformations and spline weights (`spline_weight`) for B-spline coefficients.\n",
    "\n",
    "2. **B-Spline Basis Calculation**:\n",
    "   - The `b_splines` function computes B-spline bases for given inputs, which are then used to interpolate values in the input space.\n",
    "\n",
    "3. **Spline Coefficient Computation**:\n",
    "   - The `curve2coeff` function fits spline coefficients to the data by solving a least-squares problem, ensuring that the spline interpolation matches the input-output relationship.\n",
    "\n",
    "4. **Forward Pass**:\n",
    "   - Combines the linear transformation of the input using `base_weight` and the spline interpolation using `spline_weight` to produce the output.\n",
    "\n",
    "5. **Grid Adaptation**:\n",
    "   - The `update_grid` method adjusts the spline grid based on input distribution, allowing the model to adapt dynamically to new data.\n",
    "\n",
    "6. **Regularization**:\n",
    "   - A custom loss (`regularization_loss`) penalizes the spline weights to control overfitting and ensure smooth approximations. This includes terms for weight sparsity and entropy regularization.\n",
    "\n",
    "This implementation is designed to be flexible and efficient, enabling it to approximate and learn high-dimensional functions, especially useful in tasks like function approximation, noise filtering, or PDE solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "\n",
    "shusrith_burgers_noisy_path = kagglehub.dataset_download(\"shusrith/burgers-noisy\")\n",
    "\n",
    "print(\"Data source import complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T13:23:32.523404Z",
     "iopub.status.busy": "2024-11-21T13:23:32.523064Z",
     "iopub.status.idle": "2024-11-21T13:23:35.456244Z",
     "shell.execute_reply": "2024-11-21T13:23:35.455276Z",
     "shell.execute_reply.started": "2024-11-21T13:23:32.523374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class KANLinear(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        enable_standalone_scale_spline=True,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KANLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
    "        grid = (\n",
    "            (\n",
    "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
    "                + grid_range[0]\n",
    "            )\n",
    "            .expand(in_features, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.spline_weight = torch.nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
    "        )\n",
    "        if enable_standalone_scale_spline:\n",
    "            self.spline_scaler = torch.nn.Parameter(\n",
    "                torch.Tensor(out_features, in_features)\n",
    "            )\n",
    "\n",
    "        self.scale_noise = scale_noise\n",
    "        self.scale_base = scale_base\n",
    "        self.scale_spline = scale_spline\n",
    "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
    "        self.base_activation = base_activation()\n",
    "        self.grid_eps = grid_eps\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(\n",
    "            self.base_weight, a=math.sqrt(5) * self.scale_base\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            noise = (\n",
    "                (\n",
    "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
    "                    - 1 / 2\n",
    "                )\n",
    "                * self.scale_noise\n",
    "                / self.grid_size\n",
    "            )\n",
    "            self.spline_weight.data.copy_(\n",
    "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
    "                * self.curve2coeff(\n",
    "                    self.grid.T[self.spline_order : -self.spline_order],\n",
    "                    noise,\n",
    "                )\n",
    "            )\n",
    "            if self.enable_standalone_scale_spline:\n",
    "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
    "                torch.nn.init.kaiming_uniform_(\n",
    "                    self.spline_scaler, a=math.sqrt(5) * self.scale_spline\n",
    "                )\n",
    "\n",
    "    def b_splines(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the B-spline bases for the given input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "        grid: torch.Tensor = (\n",
    "            self.grid\n",
    "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
    "        x = x.unsqueeze(-1)\n",
    "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
    "        for k in range(1, self.spline_order + 1):\n",
    "            bases = (\n",
    "                (x - grid[:, : -(k + 1)])\n",
    "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
    "                * bases[:, :, :-1]\n",
    "            ) + (\n",
    "                (grid[:, k + 1 :] - x)\n",
    "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
    "                * bases[:, :, 1:]\n",
    "            )\n",
    "\n",
    "        assert bases.size() == (\n",
    "            x.size(0),\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return bases.contiguous()\n",
    "\n",
    "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the coefficients of the curve that interpolates the given points.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
    "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
    "\n",
    "        A = self.b_splines(x).transpose(\n",
    "            0, 1\n",
    "        )  # (in_features, batch_size, grid_size + spline_order)\n",
    "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
    "        solution = torch.linalg.lstsq(\n",
    "            A, B\n",
    "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
    "        result = solution.permute(\n",
    "            2, 0, 1\n",
    "        )  # (out_features, in_features, grid_size + spline_order)\n",
    "\n",
    "        assert result.size() == (\n",
    "            self.out_features,\n",
    "            self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "        )\n",
    "        return result.contiguous()\n",
    "\n",
    "    @property\n",
    "    def scaled_spline_weight(self):\n",
    "        return self.spline_weight * (\n",
    "            self.spline_scaler.unsqueeze(-1)\n",
    "            if self.enable_standalone_scale_spline\n",
    "            else 1.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        assert x.size(-1) == self.in_features\n",
    "        original_shape = x.shape\n",
    "        x = x.reshape(-1, self.in_features)\n",
    "\n",
    "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
    "        spline_output = F.linear(\n",
    "            self.b_splines(x).view(x.size(0), -1),\n",
    "            self.scaled_spline_weight.view(self.out_features, -1),\n",
    "        )\n",
    "        output = base_output + spline_output\n",
    "\n",
    "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        batch = x.size(0)\n",
    "\n",
    "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
    "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
    "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
    "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
    "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
    "        unreduced_spline_output = unreduced_spline_output.permute(\n",
    "            1, 0, 2\n",
    "        )  # (batch, in, out)\n",
    "\n",
    "        # sort each channel individually to collect data distribution\n",
    "        x_sorted = torch.sort(x, dim=0)[0]\n",
    "        grid_adaptive = x_sorted[\n",
    "            torch.linspace(\n",
    "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
    "        grid_uniform = (\n",
    "            torch.arange(\n",
    "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
    "            ).unsqueeze(1)\n",
    "            * uniform_step\n",
    "            + x_sorted[0]\n",
    "            - margin\n",
    "        )\n",
    "\n",
    "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "        grid = torch.concatenate(\n",
    "            [\n",
    "                grid[:1]\n",
    "                - uniform_step\n",
    "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
    "                grid,\n",
    "                grid[-1:]\n",
    "                + uniform_step\n",
    "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.grid.copy_(grid.T)\n",
    "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        \"\"\"\n",
    "        Compute the regularization loss.\n",
    "\n",
    "        This is a dumb simulation of the original L1 regularization as stated in the\n",
    "        paper, since the original one requires computing absolutes and entropy from the\n",
    "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
    "        behind the F.linear function if we want an memory efficient implementation.\n",
    "\n",
    "        The L1 regularization is now computed as mean absolute value of the spline\n",
    "        weights. The authors implementation also includes this term in addition to the\n",
    "        sample-based regularization.\n",
    "        \"\"\"\n",
    "        l1_fake = self.spline_weight.abs().mean(-1)\n",
    "        regularization_loss_activation = l1_fake.sum()\n",
    "        p = l1_fake / regularization_loss_activation\n",
    "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
    "        return (\n",
    "            regularize_activation * regularization_loss_activation\n",
    "            + regularize_entropy * regularization_loss_entropy\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Model\n",
    "\n",
    "- Defines a complete Kolmogorov-Arnold Network (KAN) as a sequence of KANLinear layers for multivariate function approximation.  \n",
    "- Accepts hyperparameters like grid size, spline order, scaling factors, activation functions, and grid range to configure the architecture.  \n",
    "- Uses a `ModuleList` to stack multiple KANLinear layers based on the input hidden layer configuration (`layers_hidden`).  \n",
    "- Implements a forward pass that processes input through each KANLinear layer, optionally updating the grid dynamically for adaptability.  \n",
    "- Provides a method to compute regularization loss by aggregating the regularization terms from all layers to promote sparsity and smoothness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T13:23:40.866992Z",
     "iopub.status.busy": "2024-11-21T13:23:40.866551Z",
     "iopub.status.idle": "2024-11-21T13:23:40.874563Z",
     "shell.execute_reply": "2024-11-21T13:23:40.873740Z",
     "shell.execute_reply.started": "2024-11-21T13:23:40.866959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class KAN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_hidden,\n",
    "        grid_size=5,\n",
    "        spline_order=3,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        base_activation=torch.nn.SiLU,\n",
    "        grid_eps=0.02,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KAN, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "            self.layers.append(\n",
    "                KANLinear(\n",
    "                    in_features,\n",
    "                    out_features,\n",
    "                    grid_size=grid_size,\n",
    "                    spline_order=spline_order,\n",
    "                    scale_noise=scale_noise,\n",
    "                    scale_base=scale_base,\n",
    "                    scale_spline=scale_spline,\n",
    "                    base_activation=base_activation,\n",
    "                    grid_eps=grid_eps,\n",
    "                    grid_range=grid_range,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, update_grid=False):\n",
    "        for layer in self.layers:\n",
    "            if update_grid:\n",
    "                layer.update_grid(x)\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "        return sum(\n",
    "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
    "            for layer in self.layers\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularisation\n",
    "\n",
    "- Extends the KAN architecture by integrating dropout layers to improve regularization and prevent overfitting.  \n",
    "- Uses a `ModuleList` to stack layers, where each layer includes a KAN module, batch normalization, SiLU activation, and dropout.  \n",
    "- Configurable dropout probability allows control over the level of regularization applied during training.  \n",
    "- Implements a forward pass that processes input through each stacked layer sequentially, applying all operations in the layer pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T13:23:42.451240Z",
     "iopub.status.busy": "2024-11-21T13:23:42.450856Z",
     "iopub.status.idle": "2024-11-21T13:23:42.456797Z",
     "shell.execute_reply": "2024-11-21T13:23:42.455917Z",
     "shell.execute_reply.started": "2024-11-21T13:23:42.451211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class KANWithDropout(torch.nn.Module):\n",
    "    def __init__(self, layers_hidden, dropout_prob=0.3):\n",
    "        super(KANWithDropout, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    KAN(in_features, out_features),\n",
    "                    nn.BatchNorm1d(out_features),\n",
    "                    nn.SiLU(),\n",
    "                    nn.Dropout(dropout_prob),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function\n",
    "\n",
    "- A custom loss function combining Mean Squared Error (MSE) and L1 loss for balanced optimization between precision and robustness.  \n",
    "- The weighting factor `alpha` controls the contribution of each loss term, allowing flexibility based on the problem's requirements.  \n",
    "- Uses the `forward` method to compute the weighted sum of MSE and L1 losses between the model's output and the target values.  \n",
    "- Provides a smooth and robust loss function useful for tasks where both small errors and outlier handling are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return self.alpha * self.mse(output, target) + (1 - self.alpha) * self.l1(\n",
    "            output, target\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It has 1000 samples, push it as much as you can please till it runs out of VRAM\n",
    "\n",
    "# modify for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The clean and noisy samples of the solution are loaded for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T13:23:46.185337Z",
     "iopub.status.busy": "2024-11-21T13:23:46.184651Z",
     "iopub.status.idle": "2024-11-21T13:23:48.528705Z",
     "shell.execute_reply": "2024-11-21T13:23:48.527747Z",
     "shell.execute_reply.started": "2024-11-21T13:23:46.185304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "with h5py.File(\"/kaggle/input/burgers-noisy/simulation_data.h5\", \"r\") as f:\n",
    "    a = list(f.keys())\n",
    "    clean = []\n",
    "    noisy = []\n",
    "    for i in a[:100]:\n",
    "        clean.append(f[i][\"clean\"][:])\n",
    "        noisy.append(f[i][\"noisy\"][:])\n",
    "\n",
    "clean = np.array(clean)\n",
    "noisy = np.array(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This script processes noisy and clean data for training a model, preparing it for PyTorch's DataLoader.\n",
    "\n",
    "- **Data Reshaping**:\n",
    "  - The noisy and clean datasets are flattened from `(num_samples, height, width)` into `(num_samples, height × width)` for compatibility with PyTorch models.\n",
    "\n",
    "- **Tensor Conversion**:\n",
    "  - The flattened arrays are converted into PyTorch tensors (`X_tensor` for noisy data and `Y_tensor` for clean data) of type `float32`.\n",
    "\n",
    "- **Dataset Creation**:\n",
    "  - A `TensorDataset` pairs the noisy data (`X_tensor`) with the clean target data (`Y_tensor`) for supervised learning.\n",
    "\n",
    "- **Train/Test Split**:\n",
    "  - The dataset is split into training and testing subsets, with 80% for training and 20% for testing, using PyTorch's `random_split`.\n",
    "\n",
    "- **DataLoaders**:\n",
    "  - Training and testing datasets are wrapped into DataLoaders with a batch size of 2, enabling shuffled training and sequential testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T13:24:00.418582Z",
     "iopub.status.busy": "2024-11-21T13:24:00.417676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"Noisy data shape:\", noisy.shape)\n",
    "\n",
    "num_samples, height, width = noisy.shape\n",
    "noisy_flattened = noisy.reshape(num_samples, -1)\n",
    "clean_flattened = clean.reshape(num_samples, -1)\n",
    "\n",
    "X_tensor = torch.tensor(noisy_flattened, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(clean_flattened, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"Trainloader size:\", len(trainloader.dataset))\n",
    "print(\"Testloader size:\", len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "  - A `KANWithDropout` model is initialized with the input dimension (`input_dim`), two hidden layers of sizes 256 and 64, and a final output layer of size `input_dim` to match the input/output shape.\n",
    "  - The model is moved to the appropriate device (`GPU` if available, otherwise `CPU`).\n",
    "\n",
    "- **Optimizer**:\n",
    "  - Uses the `AdamW` optimizer, which combines the benefits of Adam with weight decay regularization to reduce overfitting.  \n",
    "  - Learning rate is set to `1e-3`, and weight decay to `1e-4`.\n",
    "\n",
    "- **Learning Rate Scheduler**:\n",
    "  - A `ReduceLROnPlateau` scheduler reduces the learning rate by a factor of 0.5 when the monitored metric (e.g., loss) stops improving for 4 epochs (`patience=4`).\n",
    "  - Minimum learning rate (`min_lr`) is set to `1e-6`, and verbose mode is enabled for logging changes.\n",
    "\n",
    "- **Loss Function**:\n",
    "  - Combines MSE and L1 losses using the `CombinedLoss` class, balancing precision and robustness during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = noisy_flattened.shape[1]  \n",
    "model = KANWithDropout([input_dim, 256, 64, 256, input_dim])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "criterion = CombinedLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This code trains the `KANWithDropout` model for 200 epochs, evaluates its validation loss, adjusts the learning rate using a scheduler, and saves the trained model.\n",
    "\n",
    "- **Training Loop**:\n",
    "  - Iterates over 200 epochs.\n",
    "  - For each batch:\n",
    "    - Moves data (`inputs` and `targets`) to the appropriate device.\n",
    "    - Clears previous gradients using `optimizer.zero_grad()`.\n",
    "    - Computes model outputs, loss, and gradients, and updates weights using `optimizer.step()`.\n",
    "    - Performs validation\n",
    "\n",
    "\n",
    "- **Learning Rate Adjustment**:\n",
    "  - The learning rate scheduler (`ReduceLROnPlateau`) adjusts the learning rate based on the validation loss, reducing it when the loss plateaus.\n",
    "\n",
    "- **Model Saving**:\n",
    "  - Saves the trained model's state dictionary (`model.state_dict()`) to a file named `\"kan_model.pth\"`, allowing for later use or deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for i, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model(inputs)\n",
    "            val_loss += criterion(output, targets).item()\n",
    "    val_loss /= len(testloader)\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Val Loss: {val_loss}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"kan_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Randomly selected sample is reshaped and prepared to be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T06:08:38.847289Z",
     "iopub.status.busy": "2024-11-21T06:08:38.846466Z",
     "iopub.status.idle": "2024-11-21T06:08:38.893230Z",
     "shell.execute_reply": "2024-11-21T06:08:38.892379Z",
     "shell.execute_reply.started": "2024-11-21T06:08:38.847249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 205824])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with  h5py.File(\"/kaggle/input/burgers-noisy/simulation_data.h5\", \"r\") as f:\n",
    "    a = f[\"10\"][\"noisy\"][:]\n",
    "    b = f[\"10\"][\"clean\"][:]\n",
    "    x = f[\"coords\"][\"x-coordinates\"][:]\n",
    "    f.close()\n",
    "a = torch.Tensor(a).to(device)\n",
    "a = a.view(1, -1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Predictions\n",
    "\n",
    "Predictions are made and the output is reshaped for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    u = model(a.to(device)).to(\"cpu\")\n",
    "\n",
    "u = u.cpu().numpy().reshape((201, 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "The `visualize_burgers` function generates an animated GIF of the Burgers equation's solution over time. It takes spatial coordinates (`xcrd`), the simulation data (`data`), and an identifier (`i`) to name the output GIF. The function iterates through the time steps of the solution, plots each one, and stores the frames for the animation. It then creates an animation using `matplotlib.animation.ArtistAnimation`, saving it as a `.gif` file with a specified frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T06:08:40.366942Z",
     "iopub.status.busy": "2024-11-21T06:08:40.366239Z",
     "iopub.status.idle": "2024-11-21T06:08:52.142127Z",
     "shell.execute_reply": "2024-11-21T06:08:52.141283Z",
     "shell.execute_reply.started": "2024-11-21T06:08:40.366895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def visualize_burgers(xcrd, data):\n",
    "    \"\"\"\n",
    "    This function animates the Burgers equation\n",
    "\n",
    "    Args:\n",
    "    path : path to the desired file\n",
    "    param: PDE parameter of the data shard to be visualized\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ims = []\n",
    "\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        if i == 0:\n",
    "            im = ax.plot(xcrd, data[i].squeeze(), animated=True, color=\"blue\")\n",
    "        else:\n",
    "            im = ax.plot(\n",
    "                xcrd, data[i].squeeze(), animated=True, color=\"blue\"\n",
    "            )  # show an initial one first\n",
    "        ims.append([im[0]])\n",
    "\n",
    "    # Animate the plot\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "\n",
    "    writer = animation.PillowWriter(fps=15, bitrate=1800)\n",
    "    ani.save(\"burgerCombo.gif\", writer=writer)\n",
    "    plt.close(fig)\n",
    "\n",
    "visualize_burgers(x[:], u)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6074846,
     "sourceId": 9943646,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
